{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tinyvisions",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zkb-g1Kj52U"
      },
      "source": [
        "#### tiny visions\n",
        "pls run this locally istg its so much faster even on an rtx2060\n",
        "\n",
        "it can run on cpu too, just change d='cpu'\n",
        "\n",
        "by [crumb](https://twitter.com/aicrumb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a0Wredah3C_"
      },
      "source": [
        "!git clone https://github.com/openai/CLIP && pip install -e ./CLIP\n",
        "import sys\n",
        "sys.path.append('./CLIP')\n",
        "from tqdm.notebook import tqdm\n",
        "import torch as t\n",
        "from torchvision.transforms import Compose, Resize, Normalize, RandomAffine, Lambda, RandomGrayscale\n",
        "import clip as c\n",
        "import PIL\n",
        "from IPython.display import display, clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_-irjwAh9TN"
      },
      "source": [
        "prompt=\"the lovers tarot card by Greg Rutkowski\"\n",
        "d='cuda'\n",
        "z=t.rand((1, 3, 256, 256), device=d, requires_grad=True)\n",
        "o=t.optim.Adam((z,),0.1)\n",
        "f=Compose([Resize(224),lambda x:t.clamp((x+1)/2,min=0,max=1),Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
        "    RandomAffine(degrees=60, translate=(0.1, 0.1)),RandomGrayscale(p=0.2),Lambda(lambda x: x + t.randn_like(x) * 0.01),])\n",
        "m=c.load('ViT-B/32', jit=False)[0].eval().requires_grad_(False).to(d)\n",
        "te=m.encode_text(c.tokenize(prompt).to(d))\n",
        "for i in tqdm(range(2000)):\n",
        "    o.zero_grad()\n",
        "    x = F.normalize(m.encode_image(t.cat([f(z.add(1).div(2)) for _ in range(4)])), dim=-1)\n",
        "    y = F.normalize(te.unsqueeze(0), dim=-1)\n",
        "    l = (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2).mean() + (z-z.clamp(-1, 1)).pow(2).mean([1,2,3]).mean()/2\n",
        "    l.backward()\n",
        "    o.step()\n",
        "PIL.Image.fromarray((z.permute(0, 2, 3, 1)*127.5+128).clamp(0,255).to(t.uint8)[0].cpu().numpy(),'RGB')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}